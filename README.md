## **Proyecto de Pipeline de Datos de Ventas**  
Este proyecto procesa y analiza datos de ventas de tiendas, realizando limpieza, transformaciÃ³n y exploraciÃ³n de relaciones entre las variables.  

---

### ðŸ“‹ **ConfiguraciÃ³n del Entorno Virtual**  
Antes de ejecutar el proyecto, asegÃºrate de configurar tu entorno virtual y las dependencias necesarias.

1. **Crear el entorno virtual**  
   ```bash
   python -m venv env
   ```

2. **Activar el entorno virtual**  
   - En Linux/Mac:  
     ```bash
     source env/bin/activate
     ```
   - En Windows:  
     ```bash
     env\Scripts\activate
     ```

3. **Instalar las dependencias**  
   ```bash
   pip install pandas numpy matplotlib seaborn scikit-learn jupyter
   ```

4. **Guardar dependencias**  
   ```bash
   pip freeze > requirements.txt
   ```
5. **Instalar dependencia openpyxl si es necesario hacerlos de forma independiente.**  
   ```bash
   pip install openpyxl
   ```
---

### ðŸ“‚ **Estructura del Proyecto**  
La estructura de carpetas y archivos estÃ¡ organizada de la siguiente manera:

```bash
/data_pipeline_project
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sales_data.xlsx  # Archivo de datos de ventas.
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ eda.ipynb        # AnÃ¡lisis exploratorio de datos.
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_preprocessing.py  # Limpieza y transformaciÃ³n.
â”‚   â”œâ”€â”€ model_training.py      # Entrenamiento del modelo.
â”‚   â””â”€â”€ utils.py               # Funciones reutilizables.
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ eda_report.pdf         # Reporte en formato PDF.
â”œâ”€â”€ main.py                    # Script principal del pipeline.
â””â”€â”€ requirements.txt           # Dependencias del proyecto.
```

---

### ðŸ“œ **DescripciÃ³n del Conjunto de Datos**  
El archivo `sales_data.xlsx` contiene informaciÃ³n sobre ventas con las siguientes caracterÃ­sticas:

| **Columna**     | **DescripciÃ³n**                                                                 |
|------------------|-------------------------------------------------------------------------------|
| **Date**        | Fecha de venta (almacenada como texto, debe convertirse a `datetime`).        |
| **Store**       | Identificador de la tienda (variable categÃ³rica).                             |
| **Category**    | CategorÃ­a del producto (Electronics, Clothing, Home Goods).                   |
| **Units_Sold**  | NÃºmero de unidades vendidas (almacenada como texto, convertir a numÃ©rico).    |
| **Unit_Price**  | Precio por unidad (almacenado como texto, convertir a numÃ©rico).              |

---

### ðŸ“Š **Patrones y Observaciones Principales**  

#### Fase 1:

1. **Estructura de los Datos**  
   - **Fechas**: 19 fechas Ãºnicas, siendo **2024-01-03** la mÃ¡s frecuente (9 repeticiones).  
   - **Tiendas**: 3 tiendas Ãºnicas, con la tienda **103** siendo la mÃ¡s frecuente (38 registros).  
   - **CategorÃ­as**: 3 categorÃ­as ("Electronics", "Clothing", "Home Goods"). La mÃ¡s repetida: **Home Goods** (38 registros).  
   - **Valores NumÃ©ricos**:  
     - **Units_Sold**: MÃ­nimos valores de venta (~20 unidades), con 25 unidades siendo el valor mÃ¡s frecuente.  
     - **Unit_Price**: Solo **3 precios diferentes**, siendo **19.99** el mÃ¡s frecuente.  

2. **Duplicados**  
   - Existen **55 filas duplicadas**. Se requiere decidir si eliminarlas o validarlas.  

3. **Valores Faltantes**  
   - No hay valores faltantes en ninguna columna.  

4. **Observaciones de VisualizaciÃ³n**  
   - La distribuciÃ³n de **Units_Sold** tiene ligera concentraciÃ³n en valores bajos.  
   - **Unit_Price** muestra Ãºnicamente 3 precios, sugiriendo baja variaciÃ³n.  

5. **Posibles Relaciones**  
   - **Precio vs. Ventas**: Los productos mÃ¡s caros parecen tener menos unidades vendidas (requiere confirmaciÃ³n).  
   - **Tendencia Temporal**: Se analizarÃ¡n patrones estacionales en ventas durante la fase de modelado.  

# Fase 2: ExplicaciÃ³n del CÃ³digo

### CÃ³digo en `data_preprocessing.py`
#### 1. Eliminar duplicados
- **`data.drop_duplicates()`**:
  - Elimina las filas duplicadas del DataFrame.
  - Se imprime la cantidad de filas duplicadas eliminadas.

#### 2. Manejo de valores nulos
- Las columnas `Units_Sold` y `Unit_Price` se convierten a tipo numÃ©rico con:
  ```python
  pd.to_numeric
  ```
- Los valores nulos se rellenan con la **mediana** de cada columna usando:
  ```python
  .fillna()
  ```

#### 3. ConversiÃ³n de fechas
- La columna `Date` se convierte al tipo `datetime` con:
  ```python
  pd.to_datetime
  ```

#### 4. CodificaciÃ³n de variables categÃ³ricas
- Se utiliza **`pd.get_dummies()`** para convertir las columnas `Store` y `Category` en variables binarias.
- El parÃ¡metro `drop_first=True` evita la multicolinealidad eliminando la categorÃ­a de referencia.

#### 5. GeneraciÃ³n de nuevas caracterÃ­sticas
- Se crea una nueva columna `Total_Sales` calculada como:
  ```python
  Units_Sold * Unit_Price
  ```

---

### CÃ³digo en `eda.ipynb`
#### 1. ConfiguraciÃ³n del entorno
- ImportaciÃ³n de bibliotecas esenciales:
  ```python
  import pandas as pd
  import seaborn as sns
  import matplotlib.pyplot as plt
  ```
- ConfiguraciÃ³n de grÃ¡ficos:
  ```python
  sns.set_theme()
  plt.rcParams['figure.figsize'] = (10, 6)
  ```

#### 2. Cargar los datos
- Se utiliza **`pd.read_csv()`** para cargar el archivo CSV:
  ```python
  data = pd.read_csv('data/sales_data.csv')
  ```
- Si las columnas no se separan correctamente, se ajustan usando:
  ```python
  .str.split()
  ```

#### 3. Importar y aplicar `preprocess_data`
- Se importa la funciÃ³n `preprocess_data` desde el script `data_preprocessing.py`:
  ```python
  from scripts.data_preprocessing import preprocess_data
  ```
- Se aplica la funciÃ³n a los datos:
  ```python
  clean_data = preprocess_data(data)
  ```

#### 4. VisualizaciÃ³n
- Se genera un histograma de la nueva columna `Total_Sales`:
  ```python
  sns.histplot(clean_data['Total_Sales'], bins=30)
  plt.title('DistribuciÃ³n de Ventas Totales')
  plt.show()
  ```
---


### ðŸš€ **EjecuciÃ³n del Proyecto**  
1. AsegÃºrate de tener activado el entorno virtual.  
2. Coloca el archivo `sales_data.xlsx` en la carpeta **data**.  
3. Ejecuta el script principal:  
   ```bash
   python main.py
   ```

---

### ðŸ“ˆ **AnÃ¡lisis Exploratorio de Datos (EDA)**  
El archivo `notebooks/eda.ipynb` contiene el anÃ¡lisis exploratorio detallado, que incluye:  
- Limpieza de datos.  
- VisualizaciÃ³n de distribuciones.  
- AnÃ¡lisis de duplicados y valores faltantes.  
- GrÃ¡ficos para observar tendencias y correlaciones.  

---

### ðŸ›  **Scripts Principales**  
- **data_preprocessing.py**: Limpieza y transformaciÃ³n de los datos.  
- **model_training.py**: Entrenamiento del modelo de predicciÃ³n.  
- **utils.py**: Funciones auxiliares reutilizables.  

---

### ðŸ›ª **Notas Finales**  
- Este pipeline es una base que puede extenderse hacia la implementaciÃ³n de modelos predictivos o dashboards interactivos.  
- AsegÃºrate de tener todas las dependencias instaladas correctamente.  

---
